{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inference_SSD_MobileNetV2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHzHGwXuFqrUFWeehYM0yW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"D5RcPu8NieLd"},"source":["%%capture\n","# After this cell executes runtime will restart to finish the install, ignore and close the crash message, continue running cells starting with the one below\n","!pip install numpy==1.17.5;\n","!pip install tensorflow-gpu==1.15.0;\n","!pip install tensorflow-object-detection-api;\n","import os\n","os.kill(os.getpid(), 9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VxxVJu0ieA3","executionInfo":{"status":"ok","timestamp":1622048257416,"user_tz":-480,"elapsed":4049,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"0dd2e7dd-872e-4e85-f507-8f96079d09c2"},"source":["%tensorflow_version 1.x\n","!pip install tf_slim"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OUn5eOwJr0zJ","executionInfo":{"status":"ok","timestamp":1622048265531,"user_tz":-480,"elapsed":347,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}}},"source":["num_steps = 20000  # A step means using a single batch of data. larger batch, less steps required\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","# Batch size 8 works well\n","MODELS_CONFIG = {\n","        'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 8\n","    }\n","}\n","selected_model = 'ssd_mobilenet_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colab's GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dewq0IjvW4ZV","executionInfo":{"status":"ok","timestamp":1622048283456,"user_tz":-480,"elapsed":10444,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"d71bcd80-2fd0-40ff-cb77-db61577a3277"},"source":["# Cloning the object detection demo flow repository\n","repo_url = 'https://github.com/GotG/object_detection_demo_flow'\n","import os\n","%cd /content\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'object_detection_demo_flow'...\n","remote: Enumerating objects: 3035, done.\u001b[K\n","remote: Total 3035 (delta 0), reused 0 (delta 0), pack-reused 3035\u001b[K\n","Receiving objects: 100% (3035/3035), 229.08 MiB | 35.01 MiB/s, done.\n","Resolving deltas: 100% (1375/1375), done.\n","Checking out files: 100% (2796/2796), done.\n","/content/object_detection_demo_flow\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4W8oIaa-NonV","executionInfo":{"status":"ok","timestamp":1622048303278,"user_tz":-480,"elapsed":2877,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"2ce3a81a-bf07-4367-c4ef-eea6d5da7783"},"source":["# Cloning repo with fine tuned model saved\n","%cd /content\n","!git clone https://github.com/AVCTY/ssd_mobilenetv2.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'ssd_mobilenetv2'...\n","remote: Enumerating objects: 259, done.\u001b[K\n","remote: Counting objects: 100% (259/259), done.\u001b[K\n","remote: Compressing objects: 100% (252/252), done.\u001b[K\n","remote: Total 259 (delta 6), reused 251 (delta 2), pack-reused 0\u001b[K\n","Receiving objects: 100% (259/259), 24.14 MiB | 33.91 MiB/s, done.\n","Resolving deltas: 100% (6/6), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nnG5kX6f1Q_","executionInfo":{"status":"ok","timestamp":1622048396109,"user_tz":-480,"elapsed":70423,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"117c0232-81e0-4f47-e02e-048809a7d93a"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/pillow/python-pil_5.1.0-1ubuntu0.5_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n","/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MKLKhZvTSIjN","executionInfo":{"status":"ok","timestamp":1622048414865,"user_tz":-480,"elapsed":744,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}}},"source":["# Set the paths\n","test_record_fname = \"/content/ssd_mobilenetv2/dataset/test/person.tfrecord\"\n","train_record_fname = \"/content/ssd_mobilenetv2/dataset/train/person.tfrecord\"\n","label_map_pbtxt_fname = \"/content/ssd_mobilenetv2/dataset/train/person_label_map.pbtxt\""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rodX6pWYtLlU","executionInfo":{"status":"ok","timestamp":1622048417467,"user_tz":-480,"elapsed":326,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"96e3bac7-4b97-45d3-8ab0-c3bea06d62e7"},"source":["output_directory = \"/content/ssd_mobilenetv2/content/models/research/fine_tuned_model\"\n","# export directory check\n","!ls {output_directory}"],"execution_count":7,"outputs":[{"output_type":"stream","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\n","frozen_inference_graph.pb\tmodel.ckpt.meta\n","model.ckpt.data-00000-of-00001\tpipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HXEOytIcSI4R","executionInfo":{"status":"ok","timestamp":1622048420015,"user_tz":-480,"elapsed":393,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}}},"source":["import os\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rp8HEA3zq5Pl","executionInfo":{"status":"ok","timestamp":1622048436837,"user_tz":-480,"elapsed":376,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"ac648fef-1eff-4fef-a2d1-caec7d531d78"},"source":["# Running inference to check what the model can detect\n","import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  \"/content/ssd_mobilenetv2/validation images\"\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['/content/ssd_mobilenetv2/validation images/image2.jpg', '/content/ssd_mobilenetv2/validation images/image4.jpg', '/content/ssd_mobilenetv2/validation images/image5.jpg', '/content/ssd_mobilenetv2/validation images/image7.jpg', '/content/ssd_mobilenetv2/validation images/image8.jpg', '/content/ssd_mobilenetv2/validation images/image6.jpg', '/content/ssd_mobilenetv2/validation images/image10.jpg', '/content/ssd_mobilenetv2/validation images/image9.jpg', '/content/ssd_mobilenetv2/validation images/image3.jpg', '/content/ssd_mobilenetv2/validation images/image1.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ztaoi_Rwrijs","executionInfo":{"status":"ok","timestamp":1622048440524,"user_tz":-480,"elapsed":426,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}}},"source":["# Configuring pipeline\n","import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"z-DPLXVrr_cT","executionInfo":{"status":"ok","timestamp":1622048444955,"user_tz":-480,"elapsed":363,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"e243ac93-24e4-4ed4-e138-cf0324bc0aa7"},"source":["# TF pretrained model checkpoint\n","DEST_DIR = '/content/models/research/pretrained_model'\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ZSS7FMUOrmHm","executionInfo":{"status":"ok","timestamp":1622048455295,"user_tz":-480,"elapsed":1784,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}}},"source":["import re\n","iou_threshold = 0.50\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    # Set number of classes num_classes.\n","    s = re.sub('iou_threshold: [0-9].[0-9]+',\n","               'iou_threshold: {}'.format(iou_threshold), s)\n","    \n","    f.write(s)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1tIJc1jLjTzDOBCKQf6NQYGAnALOyEosn"},"id":"nrbuH04yq5Wc","executionInfo":{"status":"ok","timestamp":1622048487961,"user_tz":-480,"elapsed":15576,"user":{"displayName":"Arthur Chin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRdB98tHHjC-b0VMh6Q0wKuH93BNUaUVSSFP3BjQ=s64","userId":"01992116258059764651"}},"outputId":"aac40d3e-90a2-4954-f663-26c7d08279de"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","# This is needed to display the images.\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    print(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2,\n","        skip_scores=True,\n","        skip_labels=True, )\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","    plt.show()"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"qc9yY1QrGuFF"},"source":[""],"execution_count":null,"outputs":[]}]}